SIMD -> data parallellism -> GPU 
SPMD -> multithreaded, both data parallelism and thread parallelism -> CUDA

CUDA kernel executed by array of threads (the "SP" in SPMD)
- each thread has ID ex. i = blockIdx.x * blockDim.x + threadIdx.x;
C_d[i] = A_d[i] + B_d[i];

thread array divided into multiple blocks
- cooperate via shared memory, atomic operations and barrier synchronization
- threads in diff blocks can't cooperate

sequential (host) 
kernel: launched by host; similar to C; executed on device
grid: gridDim.x, gridDim.y, gridDim.z (1D or 2D)
block: block assigned to a SM; block dimensions counted as number of threads; indices within a grid
thread: threadIdx.x etc index within a block

sample kernel:
__global__
void vecAddkernel(float* A_d, float* B_d, float* C_d, int n)
{
 int i = threadIdx.x + blockDim.x * blockIdx.x;
 if(i<n) C_d[i] = A_d[i] + B_d[i];
}

launch kernel:
 vecAddKernnel<<<ceil(n/256),256>>>(A_d, B_d, C_d, n);
